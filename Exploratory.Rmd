Survey of the State of Analytics in UK Higher and Further Education Institutions 2013
========================================================
Introduction
------------
An informal survey was undertaken by Cetis in May and June 2013. Subscribers to a number of email circulation lists - with members coming largely from institutional IT, administration and educational technology responsibilities - were invited to respond.

The purpose of the survey was to:
* Assess the current state of analytics in UK FE/HE.
* Identify the challenges and barriers to using analytics.

For the purpose of the survey, we defined our use of "analytics" to be the process of developing actionable insights through problem definition and the application of statistical models and analysis against existing and/or simulated future data. In practical terms it involves trying to find out things about an organisation, its products services and operations, to help inform decisions about what to do next.

Various domains of decision-making are encompassed: the kinds of decision that is readily understood by a business-person, whatever their line of business; questions of an essentially educational character; and decisions relating to the management of research. The line of questioning was inclusive of these three perspectives. The questions asked were:  
1. Which education sector do you work in (or with)?  
2. What is your role in your institution?  
3. In your institution which department(s) are leading institutional analytics activities and services?  
4. In your institution, how aware are staff about recent developments in analytics?  
5. Do the following roles use the results of statistical analysis such as correlation or significance testing rather than simple reporting of data in charts or tables?  
6. Which of the following sources are used to supply data for analytics activities?  
7. Which of the following data collection and analytics technologies are in place in your institution?  
8. Please name the supplier/product of the principle software in use (e.g. IBM Cognos, SPSS, Tableau, Excel)  
9. Which of the following staff capabilities are in place in your institution?  
10a. What are the drivers for taking analytics based approaches in your institution?  
10b. What are the current barriers for using of analytics in your institution?  


The survey is informal in that:
* no attempt was made to have a balanced sample, either in terms of institutional type or respondent role;
* it relied on voluntary participation, so will suffer from selection bias;
* multiple responses from a single institution may have occurred, but these cannot be identified;
* we surveyed the knowledge of individuals rather than the actual state of an organisation.

These facts, coupled with the small number of responses, means that the resulting data cannot be assumed to represent the true state of affairs but to be indicative. The report is written as a stimulus both for discussion and for more thorough investigation into some of the areas where the survey responses hint at an issue.

>Terminology: a "response" is a single submission of the survey and an "item response" pertains to a single question.

**This version is contains a number of plots created as part of an exploration of the data. A shorter version will be created for general distribution.**

```{r echo=FALSE}
#settings
echo.setting<-F #change this to hide all the source listings
fw<-7 #default figure height
fh<-7 #default figure width
col.yndnk<-c("#ee7700","#3333ff","#d0d0d0") #bar colours - order is  "yes", "no", "dont know"
col.yn<-c("#ee7700","#3333ff") #bar colours - order is yes, no
col.awareness<-c("#3333ff","#ffff33","#ee7700","#d0d0d0") #bar colours - order is "not", "some", very", "dont know"
col.stats<-c("#3333ff","#ffff33","#d0d0d0") #bar colours - order is "never", "some", "dont know"
col.staff<-rainbow(4, alpha=0.5)
#libraries
library("slam")
library("cluster")
#library(gplots)#cannot use heatmap.2 - library load causes load info to appear in knitted HTML
#useful functions
source("plotFunctions.R")
#load data
responses<-read.csv2("Cetis Analtyics Survey 2013 (Anonymised Cleaned Responses III).csv", header=T, sep=",", quote="\"", dec=".", colClasses=c("integer","factor","factor","character","integer","integer","integer","integer","integer","integer","integer", "factor","factor","factor","factor","factor","factor","numeric","character", "factor","factor","factor","factor","factor","factor","factor","numeric","character", "factor","factor","factor","factor","factor","factor","factor","factor","factor","factor","factor","numeric","character", "factor","factor","factor","factor","factor","numeric","character", "character", "factor","factor","factor","factor","numeric","character", "character","integer","integer","integer","integer","integer","integer","integer","integer","integer","integer", "character","integer","integer","integer","integer","integer","integer","integer","integer"))
```

Basic Facts
-------
```{r echo=echo.setting}
resp.count<-length(responses[,1])
```

There are `r resp.count` responses.

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
pie(table(responses[,"Q1.Sector"]),main="Which education sector do you work in (or with)?")
```


```{r fig.width=fw, fig.height=fh, echo=echo.setting}
role_T<-table(responses[,"Q2.Role"])
insideLabel.barplot(role_T[order(role_T)],Main="What us your role in your institution?", Col=rainbow(n=length(role_T), alpha=0.5))
```

Concerning the State of Knowledge
------
The line of questioning sought the knowledge of the respondent and not the actual state of affairs in a given institution. Although this fact limits the extent to which responses can be interpreted in relation to the question as asked, it does allow us to form a picture of the way knowledge of analytics activities is distributed. We can form a response to the question: what does "don't know" look like?

> Technical note: most questions contain multiple parts and for these a "don't know rating" is calculated as the proportion of parts within that question that were answered "I don't know". Question 3 contained no options so has a dont know rating of 0 or 1 only.

The mean don't know rating for each response plotted as a histogram to inspect the distribution. 

```{r echo=echo.setting}
dont.know.cols<-responses[,c("Q3.Leading.Dont.Know","Q4.Awareness.Dont.know.ratio","Q5.Use.Stats.Dont.know.ratio","Q6.Sources.Dont.know.ratio","Q7.Technologies.Dont.know.ratio","Q9.Staff.Dont.know.ratio")]
colnames(dont.know.cols)<-sub(".Dont.Know","",sub(".Dont.know.ratio","",colnames(dont.know.cols)))
dont.know.sums<-(row_sums(dont.know.cols))/6
hist(dont.know.sums)
summary(dont.know.sums)
```

The median value of 0.313 indicates that half of the sample had more than around 31%  "don't know" item responses. The 1st quartile of 0.171 indicates that 25% of the responses had around 17% or less "don't know" item responses. The conclusion is clearly that there is a lot of uncertainty. This is particularly striking because the respondents were self-selecting; it would be expected the people with the least knowledge would be less likely to respond.

The state of unknowing varies between questions? The following plot shows the mean over all responses for each question.

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
insideLabel.barplot(col_sums(dont.know.cols),Main="Per-question Don't Know Level")
```

This seems to indicate that there is a better awareness that there is something going on, both within the institution and generally (questions 3 and 4) than there is about the way an institutional response is being implemented (questions 5, 6, 7, 9). A more detailed analysis appears to indicate that questions 5 and 6 are a particular hot-spot of uncertainty, with a probable cluster of responses where the item responses for both questions were "don't know" whereas other items responses where known. In many cases, uncertainty is spread over many questions without any pattern being evident.

### Digging Deeper - patterns of "don't know" and correlation
An exploratory look to see if "don't know" for different questions appears to correlate.

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
plot(dont.know.cols)
```

Not really, although a hint between questions 5,6, and 7.

Clustering will be undertaken using the method of partitioning around medoids. This involves the selection of a given number of clusters, and the algorithmic determination of where the centre-point of these clusters are and the cluster to which each point belongs. The quality of clustering is judged using silouhette plots[1]. As a rule of thumb, a silouhette width of 0.5-0.7 is assumed to indicate a reasonable structure and values in the range 0.25-0.5 to indicate a weak structure that may be artificial. The average silhouette width can be used to indicate the overall quality of the clustering and the silhouette width of individual data points can be used to assess the quality of match of that point to the cluster, i.e. its similarity to the medoid it has been assiged compared to other medoids. In the following plots it is evident that the data cannot be described as comprising clusters but that there are sub-sets where several records are similar.

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
#http://www.unesco.org/webworld/idams/advguide/Chapt7_1_1.htm
dnk.pam2<-pam(dont.know.cols,2)
plot(dnk.pam2)
```

Clusters are centerd around (medoids have >0.5 weighting for the questions called out below):
```{r echo=echo.setting}
#get a list of the barriers indicated by each medoid
   medoids<-dnk.pam2$medoids
   apply(medoids, MARGIN=1, function(x){paste(names(x[x>0.5]), collapse=", ")})
```


3 or 4 clusters look better on the plot but look at the silhouette values.

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
dnk.pam3<-pam(dont.know.cols,3)
plot(dnk.pam3)
```
Clusters are centerd around:
```{r echo=echo.setting}
#get a list of the barriers indicated by each medoid
   medoids<-dnk.pam3$medoids
   apply(medoids, MARGIN=1, function(x){paste(names(x[x>0.5]), collapse=", ")})
```

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
dnk.pam4<-pam(dont.know.cols,4)
plot(dnk.pam4)
```
Clusters are centerd at:
```{r echo=echo.setting}
#get a list of the barriers indicated by each medoid
   medoids<-dnk.pam4$medoids
   apply(medoids, MARGIN=1, function(x){paste(names(x[x>0]), collapse=", ")})
```

Leadership of Analytics Activities
------
*In your institution which department(s) are leading institutional analytics activities and services? (multiple selection was possible)*

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
leading<-responses[,5:10]
leading.dont.know.sum<-sum(responses[,11])
colnames(leading)<-tidy.colnames(leading,"Q3.Leading")
leading_S<-col_sums(leading)
leading_S<-leading_S[order(leading_S, decreasing=F)]
insideLabel.barplot(leading_S,"Q3 Leading Analytics", Col=rev(heat.colors(n=length(leading_S), alpha=0.5)))
```

The dominant leaders reflect the centres for key institutional data and the IT services to handle it. There were only `r leading.dont.know.sum` "don't know" responses and the "other" item responses show some partial overlap with the specified categories:
```{r echo=echo.setting}
responses[leading[,6]>=1,"Q3.Leading.Text"]
```

Awareness
-----
*In your institution, how aware are staff about recent developments in analytics? (6 sub-questions, according to staff role)*

```{r echo=echo.setting}
awareness<-responses[,12:17]
awareness_T<-sapply(awareness, function(x){table(ordered(x, levels=c("Not at all","Some awareness","Very aware","I don't know")))})
colnames(awareness_T)<-tidy.colnames(awareness_T,"Q4.Awareness")
```

An impression of the general level of awareness is given by summation over all staff roles given in the question: (`r paste(tidy.colnames(awareness,"Q4.Awareness"), collapse=", ")`).

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
awareness_Agg<-apply(awareness_T, MARGIN=1, sum)
pie(awareness_Agg, main="Q4 Staff Awareness Across All Groups", col=col.awareness)
```

A stacked bar plot, ordered by increasing number of "Very aware" responses, shows the different levels of perceived awareness within each staff group:

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
op<-par(mar = c(9,4,4,2) +0.1)
barplot(awareness_T[,order(awareness_T["Very aware",])], col=col.awareness, las=2, cex.names=0.9, main="Q4 Perception of Awareness Among Staff Groups", ylab="Responses")
legend(x=4.5,y=11,rev(rownames(awareness_T)), fill=rev(col.awareness), cex=0.8, bg="#ffffff")
par(op)
```
These results are likely to be biased because of the distribution of backgrounds of respondents and this may mean that we should not assume the item responses that were not "don't know" are representative.

The tentative conclusion seems to be that, unlike many initiatives with a strong data and IT element, executive management awareness is strong. In general, the management and support roles appear to be more aware than the academic staff but the similarity between IT and library staff may not have been expected. This data suggests anyone planning to develop analytics at an institutional or sectoral level should not make too many assumptions about awareness, rather they should investigate the state.

Use of Statistical Analysis
-------
*Do the following roles use the results of statistical analysis such as correlation or significance testing rather than simple reporting of data in charts or tables? (7 sub-questions. according to staff role)*

```{r echo=echo.setting}
statAnal<-responses[,20:26]
statAnal_T<-sapply(statAnal, function(x){table(ordered(x, levels=c("Never","Sometimes","I don't know")))})
colnames(statAnal_T)<-tidy.colnames(statAnal_T,"Q5.Use.Stats")
```

Summation over all staff groups (`r paste(colnames(statAnal_T), collapse=", ")`) allows us to capture the overall impression. 

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
statAnal_Agg<-apply(statAnal_T, MARGIN=1, sum)
pie(statAnal_Agg, main="Q5 Use of Statistical Analysis Across All Groups", col=col.stats)
```

The general levels of "don't know" are really rather high. What does this tell us? Probably that reports and verbal communications do not refer to this kind of analysis. Whether this means that it is not occurring or that it is being done and not communicated would require further investigation. Arguably, whichever is the case we should be concerned; this kind of analysis is often necessary to decide whether the tables of data and charts really signify a compelling case for action. Furthermore, wider use of these well-established and routine statistical methods within an institution should probably precede use of more advanced predictive methods.

The following plot drills down into the roles and shows that the pattern is similar across several roles but has facilities/estates and finance/purchasing at an extreme. These areas should be making more use of statistical methods than the data indicates since these areas are the ones where this is most easy to do without the complexity/subtlety of teaching and learning or the uncertainties in external strategic factors; this may be an artefact of the respondent population simply not knowing what goes on in these functional areas.

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
op<-par(mar = c(9,4,4,2) +0.1)
barplot(statAnal_T[,order(statAnal_T["Never",], decreasing=T)], col=col.stats, las=2, cex.names=0.9, main="Q5 Use of Statistical Analysis Among Staff Groups", ylab="Responses")
legend(x=0.5,y=24,rev(rownames(statAnal_T)), fill=rev(col.stats), cex=0.8, bg="#ffffff")
par(op)
```

Sources of Data
-----
*Which of the following sources are used to supply data for analytics activities? (11 sub-questions, according to data source)*

Again, we must be cautious about interpreting the results; there is a large "don't know" fraction and the distribution of respondent roles/departments will have introduced bias that cannot reasonably be estimated.

The data is ordered according to the number of "yes" responses for each sub-question and shown in the following chart. Sector data includes data from the national student survey, HESA, UCAS etc.

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
dataSources<-responses[,29:39]
colnames(dataSources)<-tidy.colnames(dataSources,"Q6.Sources")
dataSources_T<-sapply(dataSources, function(x){table(ordered(x, levels=c("Yes","No","I don't know")))})
dataSources_T<-dataSources_T*100/resp.count
op <- par(mar = c(10, 4, 4, 2) + 0.1)
barplot(dataSources_T[,order(dataSources_T["Yes",], decreasing=T)], beside=F, col=col.yndnk, las=2, cex.names=0.8, main="Q6 Which Data Sources are Used?", ylab="% Responses")
legend(x=8.5, y=92, rev(rownames(dataSources_T)), fill=rev(col.yndnk), cex=1.0, bg="#ffffff")
par(op)
```

Although we should be cautious in assuming anything about the actual situation that the "don't know" responses mask - for example that the don't know fraction can be assumed to be "no" or that it can be assumed to have the same proportion of "yes" and "no" as these definitive responses - this plot suggests a few provisional comments:
* VLE data is widely used yet it only gives a partial and ambiguous view on learner activity. Given the apparent lack of use of even basic statistical methods, are we being over-confident about the value of this data?
* Collectively, VLE, attendance, and library data would give a more balanced picture of engagement yet the second two are much less widely used.
* Given the availability of sector data, what is the explanation that only half of the responses indicated it is used?
* The apparently low use of labour market data may be a missed opportunity.

Technologies in Place
-----
*Which of the following data collection and analytics technologies are in place in your institution? (5 sub-questions, according to technology)*
```{r echo=echo.setting}
techs<-responses[,42:46]
#a fix-up because there are no "Yes" responses, which would lead to techs_T being a list since the results of apply would not be of equal length.
techs_T<-sapply(techs, function(x){table(ordered(x, levels=c("Yes","No","I don't know")))})
techs_T<-techs_T*100/resp.count
colnames(techs_T)<-tidy.colnames(techs_T,"Q7.Technologies")
#techs_T.yn<-techs_T[c("Yes","No"),]
#techs_T.ynr<-100*t(t(techs_T.yn)/col_sums(techs_T.yn))
#re-order so that the greatest proportion of "yes" appears on LHS
techs_T<-techs_T[,order(techs_T["Yes",], decreasing=T)]
```


```{r fig.width=fw, fig.height=fh, echo=echo.setting}
op <- par(mar = c(8, 4, 4, 2) + 0.1)
barplot(techs_T, las=2, cex.names=0.9, col=col.yndnk, main="Q7 Which Technologies are in Place?", ylab="% Responses")
legend(x=4, y=92, rev(rownames(techs_T)), fill=rev(col.yndnk), cex=1.0, bg="#ffffff")
par(op)
```

There is some consistency across the more common technologies given in the question: data visualisation, dashboards and data warehouses. The less commonly used technologies are those with the largest number of "don't know" responses although it is plausible that some "don't know" responses for "predictive analytics" occurred because the term is imprecise. As before, we should not assume that the relative proportion of yes/no responses gives an approximate estimate of the proportion of institutions that actually employ these technologies. For data visualisation and dashboards, it might be reasonable to assume that many "don't know" responses should be substituted with "no", given that these are user-facing manifestations of analytics.

Survey respondents were asked to provide information about products/suppliers as textual item responses. Each response could contain any number of product names. The following plot shows the number of item responses for products that were named two or more times. More than 1 supplier may have been specified in a response.

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
suppliers<-list(Excel=8, SPSS=4, Cognos=2, Tableau=3, Google.Analytics=2, Qlikview=2)
insideLabel.barplot(unlist(suppliers), Main="Q7 Technology Products/Suppliers", Ylab="Responses")
```
SPSS is now part of the IBM Cognos offering, although it may be used independently of the suite.

Staff Capabilities
--------
The responses for staff capabilities show some patterns but also plausible evidence that the survey options may have lacked clarity. In particular, it is possible that the responses indicating more than 10 statisticians refer to academic statisticians rather than statisticians in a business support role. "Data Scientist" is likely to be an unfamiliar term to anyone who has not been following the technology media. A large number of "don't know" and "no", is in keeping with its newness as a concept and as a term. The two responses indicating more than 10 data scientists possibly reflects two responses from one institution at the forefront of this field.

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
staff<-responses[,50:53]
colnames(staff)<-tidy.colnames(staff,"Q9.Staff")
#the next line will impose ordering AND ensure that tabulation gives us 0 values for factor levels that are not represented in a given column
staff_T<-sapply(staff, function(x){table(ordered(x, levels=c("No","Less than 5","5 - 10", "More than 10", "I don't know")))})
staff_T<-t(staff_T)
op <- par(mar = c(7, 4, 4, 2) + 0.1)
barplot(staff_T, beside=T, las=2, col=col.staff, main="Q9 Staff Capabilities")
legend(x=1,y=15,colnames(staff), cex=0.8, fill=col.staff)
par(op)
```

A high proportion of responses indicate enthusiasts outnumber the categories of technical experts but the distribution is surprising (few responses of "5-10"). It may be significant that respondents felt most confident of their knowledge of data enthusiasts.

Drivers for Analytics
-----
*What are the drivers for taking analytics based approaches in your institution? (multiple selection was possible)*

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
drivers<-responses[,57:66]
colnames(drivers)<-tidy.colnames(drivers,"Q10a.Drivers")
drivers<-col_sums(drivers)
drivers<-drivers[order(drivers, decreasing=T)]
drivers<-drivers*100/resp.count
col.drivers<-heat.colors(length(drivers), alpha=0.5)
insideLabel.barplot(drivers, Main="Q10 Drivers for Analytics", Col=col.drivers, Ylab="% Responses")
```

The survey responses match the topics typically discussed in the literature on analytics in universities and colleges. The following suggested drivers attracted lower levels of positive response than they may deserve:
* The low value for research excellence may reflect the survey group, which contains few participants with research management responsibility and an unknown number of responses from research intensive institutions.
* Student recruitment seems to be a missed opportunity. The 50% response rate for this driver should be verified.
* Resource utilisation (excluding "human resource") is another candidate for verification. If the <60% rate is correct, it suggests opportunities for efficiency savings are being missed in too many institutions.

Barriers to Adoption
-----
*What are the current barriers for using of analytics in your institution? (multiple selection was possible)*

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
barriers<-responses[,68:75]
colnames(barriers)<-tidy.colnames(barriers,"Q10b.Barriers")
barriers_S<-col_sums(barriers)
barriers_S<-barriers_S[order(barriers_S, decreasing=T)]
barriers_S<-barriers_S*100/resp.count
col.barriers<-heat.colors(length(barriers_S), alpha=0.5)
insideLabel.barplot(barriers_S, Main="Q10 Barriers to Adoption", Col=col.barriers, Ylab="% Responses")
```

Bearing in mind that survey respondents were self-selecting, and so may have been disproportionately positive in their attitude towards analytics, the results seem to indicate that several common barriers to IT and data based initiatives arising from the attitude of people are not prevalent. The issue of lack of senior management report, which is often seen as a significant challenge, is not a major factor. This matches the earlier-noted level of awareness that is perceived among executive management. Staff and student acceptance is also not seen as an issue. This may be due to there being little practical effect on day-to-day teaching, learning, research, and support because few analytics initiatives have been rolled-out at institutional level. Even if we assume the survey is accurate, it is plausible that attitudes could change dramatically.

Whereas the attitude of people is not generally perceived as a barrier, both IT and analytical capabilities are. Among the respondents, there is a slightly greater sense that the analytical capabilities - specialised analysts and training - are common barriers than IT-related aspects - standardised data and IT resources.

A more detailed inspection shows some evidence that the IT and analytical barriers occur together whereas the attitude-based barriers are apparently randomly distributed. Three respondents only identified specialised analysis and training as barriers. No response identified zero barriers.

Respondents who stated "other" supplied: "time", "enough staff resources and priority to drive forward", "No idea, as we aren't there yet", and three counts where the field was left empty.

### Digging Deeper - patterns among barriers
Look for clusters.

A pale colour indicates the row and column are associated. The more pale, the more concentrated the association. From this, we can see that 5 responses only gave "other" - these form a redundant cluster - while a further "other" (response 12) occurred with 3 other options.

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
heatmap(as.matrix(barriers), margin=c(9,4), ylab="Response  No.")
#heatmap.2(as.matrix(barriers), margin=c(7,4), ylab="Response  No.", dendrogram="none", key=F, trace="both")
```

Try 2 clusters:
```{r fig.width=fw, fig.height=fh, echo=echo.setting}
   barriers.pam<-pam(barriers,2)
   plot(barriers.pam)
```

Clusters are centerd at:
```{r echo=echo.setting}
#get a list of the barriers indicated by each medoid
   medoids<-barriers.pam$medoids
   apply(medoids, MARGIN=1, function(x){paste(names(x[x==1]), collapse=", ")})
```

The cluster for "other" is redundant information, as noted earlier.

Try 3 clusters:

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
   barriers.pam<-pam(barriers,3)
   plot(barriers.pam)
```

Clusters are centerd at:
```{r echo=echo.setting}
   medoids<-barriers.pam$medoids
#get a list of the barriers indicated by each medoid
   apply(medoids, MARGIN=1, function(x){paste(names(x[x==1]), collapse=", ")})
```

Try 4 clusters:

```{r fig.width=fw, fig.height=fh, echo=echo.setting}
   barriers.pam<-pam(barriers,4)
   plot(barriers.pam)
```

Clusters are centerd at:
```{r echo=echo.setting}
   medoids<-barriers.pam$medoids
#get a list of the barriers indicated by each medoid
   apply(medoids, MARGIN=1, function(x){paste(names(x[x==1]), collapse=", ")})
```

Column names
------
```{r echo=echo.setting}
colnames(responses)
```

Supplementary Information
------
This report was produced by Adam Cooper and the survey was developed by Li Yuan, Sheila MacNeill, and Stephen Powell. All are members of Cetis and the work was supported by Jisc. It is licensed using the Creative Commons Attribution Licence: http://creativecommons.org/licenses/by/3.0/.

### Survey Form, Data and Source Code
These are all available from [GitHub](https://github.com/arc12/Cetis-Analytics-Survey-2013):
* Survey form (PDF)
* Raw data (CSV)
* Source code for R[2] with the cluster package[3]. This is intended for processing the raw data using knitr, which is conveniently done using [RStudio](http://www.rstudio.com/)

### References
[1]: Peter J. Rousseeuw (1987). Silhouettes: A graphical aid to the interpretation and validation of cluster analysis, Journal of Computational and Applied Mathematics, Volume 20, November 1987, Pages 53-65, ISSN 0377-0427, http://dx.doi.org/10.1016/0377-0427(87)90125-7  
[2]: R Core Team (2012). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0  
[3]: Maechler, M., Rousseeuw, P., Struyf, A., Hubert, M., Hornik, K.(2013).  cluster: Cluster Analysis Basics and Extensions. R package version 1.14.4
